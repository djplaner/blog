---
categories:
- bim
- bim2
- indicators
- lak11
date: 2011-01-12 10:25:27+10:00
next:
  text: Introducing Hunch
  url: /blog2/2011/01/13/introducing-hunch/
previous:
  text: 'Learning analytics: Definitions, processes and potential'
  url: /blog2/2011/01/10/learning-analytics-definitions-processes-and-potential/
tags:
- lak11
title: Applying "learning analytics" to BIM
type: post
template: blog-post.html
---
The following floats/records some initial ideas for connection two of my current projects, [BIM](/blog2/research/bam-blog-aggregation-management/) and [lak11](http://www.learninganalytics.net/). The ideas arise out of some discussion with my better half who is currently using BIM in one of the courses she is teaching.

Some brief background, BIM is a Moodle module that allows teaching staff to manage and encourage the use of individual student blogs. The blogs are hosted by an external blog provider of the student's choice, not within Moodle. Typical use is to encourage reflection and make visible student work in order for comments and discussion.

### BIM participation as indicator

The discussion started with the observation that by the second or third required blog post it was generally possible to identify the students in a course that would do really good and those that would do really bad. How and when the students provided their blog posts is a good indicator of overall result.

This correlation was first observed with my first use of [BAM in 2006](/blog2/publications/blogs-reflective-journals-and-aggregation-an-initial-experiment/#predictor) (BIM stands for BAM into Moodle) and some findings of others.

This correlation was not something that was new. We were both able to make the observation that similar sorts of patterns exist with most educational practices. The difference is that the nature of the BIM assignments generally makes this more obvious. The discussion turned to what this pattern actually tells us?

### Students with good practices

We ended up agreeing (as much as we ever do) that what this pattern is showing us is not that some students are smart and that some are not. Instead it is showing us that the "really good" students simply have the "really good" study practices. They are the ones reading the material, reflecting upon it and engaging with the assessment requirements. The "really bad" students just never get going for whatever reason. The rest of the students are generally engaging in the work at a surface level.

So, use of BIM is making this pattern more obvious, what should be done about it?

### Encouraging connections

The tag line for the [lak11 course](http://www.learninganalytics.net/) is

> Analyzing what can be connected

A thought that "connects" with me and what I think analytics might be good for. More specifically, my interest in analytics is focused more at the idea of

> Using analysis to encourage connections

Which going by the definitions given in [one of the early readings](/blog2/2011/01/10/learning-analytics-definitions-processes-and-potential/) is close to what is meant by action analytics.

In the case of BIM, the idea consists of two tasks

1. Analyse what is going on within BIM to identify patterns; and then
2. Bring those patterns/analysis to the attention of the folk associated with a course in order to encourage action.

### Some ideasOne idea

This leads to some ideas for additional features for bim. None, bits or all of them might get implemented.

#### Connect students with evidence of good practice

1. Add a due date to each question a student is meant to respond to within a bim activity.
2. Allow academic staff to choose (or perhaps create) a warning regimen.
3. A warning regimen would be specify a list of messages to send to individual students based on the due date and the student's own contributions to the bim activity. The specification might include
    - Time when to send messages.  
        e.g. 1 week, 3 days and on the day.
    - Teacher provided content of the message.
    - Some bim analysis around the activity.  
        e.g. it might include the number of students who have already submitted answers to the question, perhaps some summary of connections from previous uses of bim between when posts are submitted and overall performance. Some statistics or data about the posts so far e.g. amount of words, some textual statistics etc.
    - Links to other posts.  
        This one could be seen as questionable. Links to other student posts could act as scaffolding for students not really sure what to post. Of course, the "scaffolding" could result in "copying".

The idea being that being aware of what other students are posting or what is considered good practice would potentially encourage students, or at least make it more likely, that they may consider such practice.

This is very close to the idea behind Michael De Raadt's [progress bar](http://www.sci.usq.edu.au/staff/deraadt/progressBar.html) for Moodle.

### What "theories" exist?

[One of the initial readings](/blog2/2011/01/10/learning-analytics-definitions-processes-and-potential/) identified four main class of components for learning analytics. One of which is theory, which includes the statistical and data mining techniques that can be applied to the data.

I need to spend some time looking at what theories exist that might apply to BIM. e.g. I'm wondering if some of the textual analysis algorithms might provide a good proxy for evaluating the quality of blog posts and whether or not there might be some patterns/correlations with final/overall student results.